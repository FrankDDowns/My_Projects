{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d7d81-997e-4511-8931-0b44a5469ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f_oneway, shapiro, levene, kruskal, sem\n",
    "import scipy.stats as st \n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import scikit_posthocs as sp\n",
    "import numpy as np\n",
    "import string\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f941e06-a9ef-403a-98c5-75353a0ad638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manditory column order ['date', 'country', 'Subject', 'events']\n",
    "dfc = pd.read_csv('search_data_pest.csv')\n",
    "sub = dfc.columns[2]\n",
    "print(dfc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776feeb-fa06-40cd-a3f5-ab5781b8d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format date column\n",
    "dfc['date'] = pd.to_datetime(dfc['date'], format='%d-%b-%y', dayfirst=True)\n",
    "print(dfc.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5799b88-002f-4bdf-a135-7743601ad647",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Compact letter display algorithm</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f09ba-b48c-44fb-8051-5f281e949220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cld_al(df, alpha=0.1):\n",
    "\n",
    "    df[\"p-adj\"] = df[\"p-adj\"].astype(float)\n",
    "\n",
    "    # Creating a list of the different treatment groups from Tukey's\n",
    "    group1 = set(df.group1.tolist())  # Dropping duplicates by creating a set\n",
    "    group2 = set(df.group2.tolist())  # Dropping duplicates by creating a set\n",
    "    groupSet = group1 | group2  # Set operation that creates a union of 2 sets\n",
    "    groups = sorted(list(groupSet))\n",
    "\n",
    "    # Creating lists of letters that will be assigned to treatment groups\n",
    "    letters = list(string.ascii_lowercase)[:len(groups)]\n",
    "    cldgroups = letters\n",
    "\n",
    "    # the following algoritm is a simplification of the classical cld,\n",
    "\n",
    "    cld = pd.DataFrame(list(zip(groups, letters, cldgroups)))\n",
    "    cld[3]=\"\"\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        if df[\"p-adj\"][row[0]] > (alpha):\n",
    "            cld.iat[groups.index(df[\"group1\"][row[0]]), 2] += cld.iat[groups.index(df[\"group2\"][row[0]]), 1]\n",
    "            cld.iat[groups.index(df[\"group2\"][row[0]]), 2] += cld.iat[groups.index(df[\"group1\"][row[0]]), 1]\n",
    "            \n",
    "        if df[\"p-adj\"][row[0]] < (alpha):\n",
    "                cld.iat[groups.index(df[\"group1\"][row[0]]), 3] +=  cld.iat[groups.index(df[\"group2\"][row[0]]), 1]\n",
    "                cld.iat[groups.index(df[\"group2\"][row[0]]), 3] +=  cld.iat[groups.index(df[\"group1\"][row[0]]), 1]\n",
    "\n",
    "    cld[2] = cld[2].apply(lambda x: \"\".join(sorted(x)))\n",
    "    cld[3] = cld[3].apply(lambda x: \"\".join(sorted(x)))\n",
    "    cld.rename(columns={0: \"groups\"}, inplace=True)\n",
    "\n",
    "    # this part will reassign the final name to the group\n",
    "    # for sure there are more elegant ways of doing this\n",
    "    cld = cld.sort_values(cld.columns[2], key=lambda x: x.str.len())\n",
    "    cld[\"labels\"] = \"\"\n",
    "    letters = list(string.ascii_lowercase)\n",
    "    unique = []\n",
    "    for item in cld[2]:\n",
    "\n",
    "        for fitem in cld[\"labels\"].unique():\n",
    "            for c in range(0, len(fitem)):\n",
    "                if not set(unique).issuperset(set(fitem[c])):\n",
    "                    unique.append(fitem[c])\n",
    "        g = len(unique)\n",
    "\n",
    "        for kitem in cld[1]:\n",
    "            if kitem in item:\n",
    "                if cld[\"labels\"].loc[cld[1] == kitem].iloc[0] == \"\":\n",
    "                    cld[\"labels\"].loc[cld[1] == kitem] += letters[g]\n",
    "\n",
    "                #Checking if there are forbidden pairing (proposition of solution to the imperfect script)                \n",
    "                if kitem in ' '.join(cld[3][cld[\"labels\"]==letters[g]]): \n",
    "                    g=len(unique)+1\n",
    "               \n",
    "                # Checking if columns 1 & 2 of cld share at least 1 letter\n",
    "                if len(set(cld[\"labels\"].loc[cld[1] == kitem].iloc[0]).intersection(cld.loc[cld[2] == item, \"labels\"].iloc[0])) <= 0:\n",
    "                    if letters[g] not in list(cld[\"labels\"].loc[cld[1] == kitem].iloc[0]):\n",
    "                        cld[\"labels\"].loc[cld[1] == kitem] += letters[g]\n",
    "                    if letters[g] not in list(cld[\"labels\"].loc[cld[2] == item].iloc[0]):\n",
    "                        cld[\"labels\"].loc[cld[2] == item] += letters[g]\n",
    "\n",
    "    cld = cld.sort_values(\"labels\")\n",
    "    #print(cld)\n",
    "    #print('\\n')\n",
    "    cld.drop(columns=[1, 2, 3], inplace=True)\n",
    "    #print(cld)\n",
    "    #print('\\n')\n",
    "    #print('\\n')\n",
    "    return(cld)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e2a4b7-8ef2-4603-b3c3-6e780ddf1126",
   "metadata": {},
   "source": [
    "<font size=\"5\"> ANOVA loop</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958d09c-77e3-4277-8db1-5deddf30af3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create df ANOVA for results  \n",
    "test_results = pd.DataFrame(columns=['test', 'country', sub, 'F/H-statistic', 'p-value'])\n",
    "\n",
    "\n",
    "country_index = 0\n",
    "\n",
    "\n",
    "# Testing loop \n",
    "for country in dfc['country'].unique():\n",
    "    filtered_country_df = dfc[dfc['country'] == country]\n",
    "    country_index += 1\n",
    "    print('country ', country_index, '/', len(dfc['country'].unique()), ' Started.')\n",
    "    sub_index = 0\n",
    "    \n",
    "    for subject in filtered_country_df[sub].unique():\n",
    "        filtered_df = filtered_country_df[filtered_country_df[sub] == subject]\n",
    "        sub_index +=1\n",
    "        print('Subject ', sub_index,'/', len(filtered_country_df[sub].unique()), 'in country ', country_index,'/',len(dfc['country'].unique()), ' Started.')\n",
    "\n",
    "        # Test data assumptions/requirements\n",
    "        if len(filtered_df['date'].dt.month.unique()) >= 3:\n",
    "            print('groups for ', country, 'and ', subject, 'are sufficient')\n",
    "            # Specify the date range\n",
    "            start_date = '2021-10-01'\n",
    "            end_date = '2023-09-30'\n",
    "            date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "            # Create a df with the date range\n",
    "            date_range_df = pd.DataFrame({'date': date_range})\n",
    " \n",
    "            # Merge existing data with the date range, filling missing values with zeros and specified crop name\n",
    "            filtered_df = pd.merge(date_range_df, filtered_df, on='date', how='left').fillna({'events': 0, sub : subject, 'country': country})\n",
    "            filtered_df['month'] = filtered_df['date'].dt.month\n",
    "            filtered_df['year'] = filtered_df['date'].dt.year\n",
    "\n",
    "            \n",
    "            #Average data by month \n",
    "            filtered_df['events'] = pd.to_numeric(filtered_df['events'], errors='coerce')\n",
    "            \n",
    "            # Check normality\n",
    "            _, p_normality = shapiro(filtered_df['events'])\n",
    "            print(country , subject , p_normality)\n",
    "            # Check homogeneity of variances\n",
    "            _, p_homogeneity = levene(filtered_df['events'], filtered_df['month'])\n",
    "            print(country , subject , p_homogeneity)\n",
    "\n",
    "            # check p values and proceed as required\n",
    "            if p_normality < 0.05 and p_homogeneity < 0.05:\n",
    "\n",
    "                \n",
    "                # The data assumptions are met so proceed with ANOVA test \n",
    "                print('ANOVA performed for ', country, 'and ', subject,)\n",
    "                model = AnovaRM(filtered_df, 'events', 'year', within=['month'], aggregate_func='sum')\n",
    "                results = model.fit()\n",
    "                print(results.summary())\n",
    "                first_row = results.anova_table.iloc[0]\n",
    "                f_statistic = first_row['F Value']\n",
    "                print(f_statistic)\n",
    "                p_value = p_value = first_row['Pr > F']\n",
    "                print(p_value)\n",
    "                dict_res ={ \n",
    "                    'test': 'ANOVA',\n",
    "                    'country': country,\n",
    "                    sub : subject,\n",
    "                    'F/H-statistic': float(f_statistic),\n",
    "                    'p-value': float(p_value)\n",
    "                }\n",
    "                test_results = (\n",
    "                    pd.DataFrame([dict_res]).copy() if test_results.empty \n",
    "                    else pd.concat([test_results, pd.DataFrame([dict_res])], ignore_index=True)\n",
    "                )\n",
    "            \n",
    "            #The data assumptions are not met so proceed with the Kruskal-Wallis test \n",
    "            else:\n",
    "                #Proceed with the Kruskal-Wallis test \n",
    "                print('kruskal performed for ', country, 'and ', subject,)\n",
    "                h_statistic, p_value_kruskal = kruskal(filtered_df['month'], filtered_df['events'])\n",
    "                #print(p_value_kruskal)\n",
    "                dict_res ={ \n",
    "                    'test': 'Kruskal',\n",
    "                    'country': country,\n",
    "                    sub : subject,\n",
    "                    'F/H-statistic': float(h_statistic),\n",
    "                    'p-value': float(p_value_kruskal)\n",
    "                }\n",
    "             \n",
    "                test_results = (\n",
    "                    pd.DataFrame([dict_res]).copy() if test_results.empty \n",
    "                    else pd.concat([test_results, pd.DataFrame([dict_res])], ignore_index=True)\n",
    "                )\n",
    "                \n",
    "        # Not enough samples to run the test\n",
    "        else:\n",
    "            print('not enough for ', country, 'and ', subject)\n",
    "            dict_res ={ \n",
    "                    'test': 'Not enough data',\n",
    "                    'country': country,\n",
    "                    sub : subject,\n",
    "                    'F/H-statistic': 0,\n",
    "                    'p-value': 0\n",
    "                }\n",
    "            \n",
    "            test_results = (\n",
    "                    pd.DataFrame([dict_res]).copy() if test_results.empty \n",
    "                    else pd.concat([test_results, pd.DataFrame([dict_res])], ignore_index=True)\n",
    "                )\n",
    "\n",
    "test_results.to_csv(sub+' results.csv', index=False)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eaedb0-dd6c-4a9f-a42f-12f6359216a8",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Tukey loop (ANOVA follow up)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e641cc8-2f34-4e2c-844f-30966c941564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA follow up\n",
    "anova_results = test_results[test_results['test'] == 'ANOVA']\n",
    "tukey_results = pd.DataFrame(columns=['country', sub, 'group1', 'group2', 'meandiff', 'p-adj', 'lower', 'upper', 'reject'])\n",
    "graph_data_df = pd.DataFrame(columns=['country', sub,'month', 'events_mean', 'events_std','confidence_interval', 'labels', 'groups'])\n",
    "test_index = 0\n",
    "\n",
    "for index, row in anova_results.iterrows():\n",
    "    \n",
    "    test_index += 1 \n",
    "    print('test ', test_index, '/', len(anova_results), ' started')\n",
    "    \n",
    "    p_value = row['p-value']\n",
    "    \n",
    "    if p_value < 0.1:\n",
    "        \n",
    "        filtered_anova_df = dfc[(dfc['country'] == row['country']) & (dfc[sub] == row[sub])]\n",
    "        temp_country = row['country']\n",
    "        temp_crop = row[sub]\n",
    "      \n",
    "        # Specify the date range\n",
    "        start_date = '2021-10-01'\n",
    "        end_date = '2023-09-30'\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "        # Create a df with the date range\n",
    "        date_range_df = pd.DataFrame({'date': date_range})\n",
    " \n",
    "        # Merge existing data with the date range, filling missing values with zeros and specified crop name\n",
    "        filtered_anova_df = pd.merge(date_range_df, filtered_anova_df, on='date', how='left').fillna({'events': 0, sub : row[sub], 'country': row['country']})\n",
    "        filtered_anova_df['month'] = filtered_anova_df['date'].dt.month\n",
    "        filtered_anova_df['year'] = filtered_anova_df['date'].dt.year\n",
    "\n",
    "        # Agregate data by month \n",
    "        filtered_anova_df['events'] = pd.to_numeric(filtered_anova_df['events'], errors='coerce')\n",
    "        filtered_anova_df = filtered_anova_df.groupby(['year', 'month'])['events'].sum().reset_index()\n",
    "        filtered_anova_df.sort_values(by='month', inplace=True)\n",
    "\n",
    "        #prep graph data \n",
    "        graph_data = filtered_anova_df.groupby('month')['events'].agg(['mean', 'std', 'count', 'sem']).reset_index()\n",
    "        graph_data['samp_count'] = graph_data['month'].map(filtered_anova_df['month'].value_counts())\n",
    "        graph_data.columns = ['month', 'events_mean', 'events_std', 'count', 'sem', 'samp_count']\n",
    "        graph_data['confidence_interval'] = graph_data.apply(\n",
    "    lambda row: st.t.interval(0.90, loc=row['events_mean'], scale=row['sem'], df=row['samp_count']-1) if row['events_mean'] != 0 else (0, 0),\n",
    "    axis=1\n",
    ")\n",
    "        print(temp_country + \" \" + temp_crop)\n",
    "        print(graph_data.head(12))\n",
    "              \n",
    "        #scale=row['events_std'] / np.sqrt(row['count'])), axis=1)\n",
    "        graph_data['country'] = temp_country\n",
    "        graph_data[sub] = temp_crop\n",
    "        \n",
    "\n",
    "        # run Tukey test\n",
    "        tukey = pairwise_tukeyhsd(endog=filtered_anova_df['events'], groups=filtered_anova_df['month'], alpha=0.1)\n",
    "        if tukey.reject.any():\n",
    "            print(row['country'], row[sub], ' valid')\n",
    "            tukey_df = pd.DataFrame(data=tukey._results_table.data[1:], columns=tukey._results_table.data[0])\n",
    "            tukey_df['country'] = row['country']\n",
    "            tukey_df[sub] = row[sub]\n",
    "            \n",
    "\n",
    "            # Get the result summary as a DataFrame\n",
    "            tukey_summary = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])\n",
    "\n",
    "            #CLD algarythem \n",
    "            cld_data = cld_al(tukey_summary, alpha=0.1)\n",
    "\n",
    "            #merge CLD with data \n",
    "            merged_df = pd.merge(graph_data, cld_data, left_on='month', right_on='groups')\n",
    "            merged_df = merged_df[['country', sub ,'month', 'events_mean', 'events_std','confidence_interval', 'labels', 'groups']]\n",
    "            \n",
    "\n",
    "            #concatonate tables\n",
    "            tukey_results = (tukey_df.copy() if tukey_results.empty else pd.concat([tukey_results, tukey_df], ignore_index=True))\n",
    "            graph_data_df = (merged_df.copy() if graph_data_df.empty else pd.concat([graph_data_df, merged_df], ignore_index=True))\n",
    "\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print(row['country'], row[sub] + ' False')\n",
    "\n",
    "\n",
    "tukey_results.to_csv(sub+' tukey_results.csv', index=False)\n",
    "\n",
    "print('complete')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b1ed4-c7a7-4491-845b-8a069d71079a",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Plot graphs with CLD and confidence intervals</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03464ff5-e473-42dc-a85d-ab80633f0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create plots and save them to pdf\n",
    "pdffile = PdfPages(sub+' graph.pdf')\n",
    "\n",
    "#graph_data_df.sort_values(by=sub, inplace=True)\n",
    "plt.figure()\n",
    "\n",
    "country_index = 0\n",
    "print(graph_data_df.head())\n",
    "\n",
    "for country in graph_data_df['country'].unique():\n",
    "    country_index += 1\n",
    "    print('country ', country_index, '/', len(graph_data_df['country'].unique()), ' Started.')\n",
    "    sub_index = 0\n",
    "\n",
    "    temp_filterd_graph_df = graph_data_df[graph_data_df['country'] == country]\n",
    "    \n",
    "\n",
    "    for subject in temp_filterd_graph_df[sub].unique():     \n",
    "        sub_index +=1\n",
    "        print('Subject ', sub_index,'/', len(temp_filterd_graph_df[sub].unique()), 'in country ', country_index,'/',len(graph_data_df['country'].unique()), ' Started.')\n",
    "        \n",
    "        filterd_graph_df = temp_filterd_graph_df [temp_filterd_graph_df[sub] == subject]\n",
    "\n",
    "        \n",
    "        x_values = filterd_graph_df['month']\n",
    "        y_values = filterd_graph_df['events_mean']\n",
    "        std_values = filterd_graph_df['events_std']\n",
    "        data_label = filterd_graph_df['labels']\n",
    "        lower_ci = filterd_graph_df['confidence_interval'].apply(lambda x: x[0])\n",
    "        upper_ci = filterd_graph_df['confidence_interval'].apply(lambda x: x[1])\n",
    "        confidence_interval = [y_values - lower_ci, upper_ci - y_values]\n",
    "        standard_error = filterd_graph_df['sem']\n",
    "\n",
    "        # Plotting the bar chart with confidence intervals as error bars\n",
    "        plt.bar(x_values, y_values, yerr = standard_error, capsize=5, label='Events', color='blue')\n",
    "                \n",
    "        # Adding data labels\n",
    "        for x, y, label in zip(x_values, y_values, data_label):\n",
    "            plt.text(x, y + 0.02, f'{label}', ha='center', va='bottom') \n",
    "\n",
    "        # Adding labels and title    \n",
    "        plt.xlabel('Month')\n",
    "        plt.ylabel('Events')\n",
    "        plt.title(country + subject)\n",
    "        plt.legend()\n",
    "        pdffile.savefig()\n",
    "        plt.close()\n",
    "    \n",
    "pdffile.close()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86b657-7c3c-48a1-9e61-281479a75ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
