{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80bd9c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda  used\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device, ' used')\n",
    "# Load SqueezeNet\n",
    "squeezenet = models.squeezenet1_1(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b0eb2a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a608ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the output layer for binary classification\n",
    "    #access the 2nd layer of the model\n",
    "in_features = squeezenet.classifier[1].in_channels\n",
    "\n",
    "    #kernal_size = larger number increase to learn from larger patterns at the cost of computational demand \n",
    "    #stride = larger number reduces number of pixels sampled reducing computational demand \n",
    "squeezenet.classifier[1] = torch.nn.Conv2d(in_features, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "# Image format requirments. Models tend to be trained on image sizes of 224. It is important to maintain aspect ration. \n",
    "    #transforms.ToTensor formats the image to be compatable with the model. \n",
    "transform = transforms.Compose([transforms.Resize((224, )),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# Retriving the data source and applying transofmation. \n",
    "\n",
    "#data source type 1\n",
    "##dataset = datasets.ImageFolder(root='path/to/mosquito_dataset', transform=transform)\n",
    "\n",
    "# Randomly splits the dataset into training and validation sets. 80% train and 20% validation is a common ratio. \n",
    "##train_size = int(0.8 * len(dataset))\n",
    "##val_size = len(dataset) - train_size\n",
    "##train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "#data source type 2\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\n",
    "                                     'D:\\Programming stuff\\Machine learning\\Training_data\\Data\\Training',transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=\n",
    "                                     'D:\\Programming stuff\\Machine learning\\Training_data\\Data\\Validation',transform=transform)\n",
    "\n",
    "print('data loaded')\n",
    "\n",
    "\n",
    "# Defining data loader settings to optimize processing.  \n",
    "batch_size = 32\n",
    "\n",
    "    #shuffling training data is important for preventing the model from learning the order. \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #shuffling is not needed on validation data as a consisten order makes it easier to track performance. \n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Loss Function - quantifies how well the model is performing by calculating difference between predicted output and true labels.\n",
    "    #for a binary model 'torch.nn.CrossEntropyLoss' is commenly used.     \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer - responsible for adjusting the model's parameters during the training process. \n",
    "    #lr'learning rate' controls the the size of changes made in the model.  \n",
    "    #Adam - adaptive moment estimation. Well-suited for many tasks. Maintains adaptive learning rates.\n",
    "optimizer = optim.Adam(squeezenet.parameters(), lr=0.001)\n",
    "    \n",
    "    #SGD - Updates parameters in the opposite direction of gradient. Require careful tuning of the learning rate.\n",
    "#optimizer = optim.SGD(squeezenet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "print('training loop started')\n",
    "#Training loop \n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    squeezenet = squeezenet.cuda()\n",
    "    squeezenet.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad() #removes gradiant from previous epoch\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()  # Move data to GPU\n",
    "        outputs = squeezenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() #calculates gradiants \n",
    "        optimizer.step() #adjust paramaters based on gradiants \n",
    "\n",
    "    # Validation\n",
    "    squeezenet.eval()\n",
    "    with torch.no_grad(): #Disables gradiant calculations\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()  # Move data to GPU\n",
    "            outputs = squeezenet(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = total_correct / total_samples\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {accuracy:.4f}')\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ebf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab600e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Desired Kernel Name",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
